# ==================== 优化版Docker Compose配置 ====================
# 针对性能优化：资源限制、网络优化、水平扩展支持

version: '3.8'

x-inference-service-template: &inference-service-template
  image: tensorflow/serving
  volumes:
    - ./tf_serving_model:/models
    - ./batching_config.txt:/models/batching_config.txt
  environment:
    - MODEL_NAME=bert-chinese
    - TFSERVING_BATCHING_PARAMETERS_FILE=/models/batching_config.txt
  command:
    - "--enable_batching=true"
    - "--batching_parameters_file=/models/batching_config.txt"
    - "--rest_api_num_threads=8"
    - "--rest_api_timeout_in_ms=60000"
  restart: unless-stopped
  healthcheck:
    test: ["CMD", "curl", "-f", "http://localhost:8501/v1/models/bert-chinese"]
    interval: 30s
    timeout: 10s
    retries: 3
    start_period: 60s

services:
  # ==================== 多实例TF Serving ====================
  inference-service-1:
    <<: *inference-service-template
    container_name: inference-service-1
    ports:
      - "8502:8501"
  inference-service-2:
    <<: *inference-service-template
    container_name: inference-service-2
    ports:
      - "8503:8501"
  inference-service-3:
    <<: *inference-service-template
    container_name: inference-service-3
    ports:
      - "8504:8501"

  # ==================== Nginx负载均衡器 ====================
  nginx:
    image: nginx:alpine
    container_name: tfserving-nginx
    ports:
      - "8501:8501"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - inference-service-1
      - inference-service-2
      - inference-service-3
    restart: unless-stopped

  # ==================== API网关服务 ====================
  api-gateway:
    build:
      context: .
      dockerfile: Dockerfile.optimized
    container_name: api-gateway-optimized
    ports:
      - "5001:5001"
    volumes:
      - ./saved_model:/app/saved_model
    environment:
      - TF_SERVING_URL=http://nginx:8501/v1/models/bert-chinese:predict
    depends_on:
      - nginx
    restart: unless-stopped

# ==================== 网络配置 ====================
networks:
  default:
    driver: bridge
    # 网络优化配置
    driver_opts:
      com.docker.network.bridge.name: bert-network

# ==================== 卷配置 ====================
volumes:
  model_data:
    driver: local 