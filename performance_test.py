#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
BERTä¸­æ–‡æ–‡æœ¬åˆ†ç±»APIæ€§èƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•ç»´åº¦ï¼šå“åº”æ—¶é—´ã€å¹¶å‘èƒ½åŠ›ã€ååé‡ã€é”™è¯¯ç‡
"""

import time
import json
import requests
import threading
import statistics
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
import matplotlib.pyplot as plt
import numpy as np

class PerformanceTester:
    def __init__(self, base_url="http://localhost:5001"):
        self.base_url = base_url
        self.test_texts = [
            "è¿™æ‰‹æœºæ‹ç…§çœŸå¥½çœ‹ï¼Œæˆ‘å¾ˆå–œæ¬¢ï¼",
            "è´¨é‡å¤ªå·®äº†ï¼Œä¸æ¨èè´­ä¹°ã€‚",
            "è¿™ä¸ªäº§å“çš„åŠŸèƒ½æ¯”è¾ƒé½å…¨ï¼Œä»·æ ¼ä¹Ÿåˆç†ã€‚",
            "æœåŠ¡æ€åº¦å¾ˆå¥½ï¼Œç‰©æµä¹Ÿå¾ˆå¿«ã€‚",
            "ä»·æ ¼æœ‰ç‚¹è´µï¼Œä½†æ˜¯è´¨é‡ç¡®å®ä¸é”™ã€‚",
            "ä¸é”™",
            "è¿™æ¬¾æ‰‹æœºçš„è®¾è®¡éå¸¸ç²¾ç¾ï¼Œå¤–è§‚æ—¶å°šå¤§æ°”ï¼Œæ‰‹æ„Ÿä¹Ÿå¾ˆå¥½ã€‚",
            "å±å¹•æ˜¾ç¤ºæ•ˆæœæ¸…æ™°ï¼Œè‰²å½©é²œè‰³ï¼Œè§‚çœ‹è§†é¢‘å’Œç©æ¸¸æˆéƒ½å¾ˆäº«å—ã€‚",
            "æ‹ç…§åŠŸèƒ½å¼ºå¤§ï¼Œå¤œæ™¯æ¨¡å¼ç‰¹åˆ«å‡ºè‰²ï¼Œèƒ½å¤Ÿæ‹å‡ºå¾ˆæ¸…æ™°çš„ç…§ç‰‡ã€‚",
            "ç”µæ± ç»­èˆªèƒ½åŠ›ä¹Ÿä¸é”™ï¼Œæ­£å¸¸ä½¿ç”¨ä¸€å¤©æ²¡é—®é¢˜ã€‚"
        ]
        
    def single_request_test(self, text):
        """å•æ¬¡è¯·æ±‚æµ‹è¯•"""
        start_time = time.time()
        try:
            response = requests.post(
                f"{self.base_url}/predict",
                json={"text": text},
                headers={"Content-Type": "application/json"},
                timeout=30
            )
            end_time = time.time()
            
            if response.status_code == 200:
                result = response.json()
                return {
                    "success": True,
                    "response_time": (end_time - start_time) * 1000,  # è½¬æ¢ä¸ºæ¯«ç§’
                    "status_code": response.status_code,
                    "confidence": result.get("confidence", 0),
                    "text_length": len(text)
                }
            else:
                return {
                    "success": False,
                    "response_time": (end_time - start_time) * 1000,
                    "status_code": response.status_code,
                    "error": response.text
                }
        except Exception as e:
            end_time = time.time()
            return {
                "success": False,
                "response_time": (end_time - start_time) * 1000,
                "error": str(e)
            }
    
    def baseline_test(self, num_requests=10):
        """åŸºçº¿æµ‹è¯•ï¼šé¡ºåºè¯·æ±‚"""
        print(f"ğŸ” åŸºçº¿æµ‹è¯•ï¼š{num_requests}ä¸ªé¡ºåºè¯·æ±‚")
        print("=" * 50)
        
        results = []
        for i in range(num_requests):
            text = self.test_texts[i % len(self.test_texts)]
            result = self.single_request_test(text)
            results.append(result)
            
            if result["success"]:
                print(f"è¯·æ±‚ {i+1:2d}: {result['response_time']:6.2f}ms | "
                      f"ç½®ä¿¡åº¦: {result['confidence']:.3f} | "
                      f"æ–‡æœ¬é•¿åº¦: {result['text_length']}")
            else:
                print(f"è¯·æ±‚ {i+1:2d}: å¤±è´¥ - {result.get('error', 'Unknown error')}")
        
        self._analyze_results(results, "åŸºçº¿æµ‹è¯•")
    
    def concurrent_test(self, num_requests=50, max_workers=10):
        """å¹¶å‘æµ‹è¯•"""
        print(f"\nğŸš€ å¹¶å‘æµ‹è¯•ï¼š{num_requests}ä¸ªè¯·æ±‚ï¼Œ{max_workers}ä¸ªå¹¶å‘çº¿ç¨‹")
        print("=" * 50)
        
        results = []
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_text = {
                executor.submit(self.single_request_test, self.test_texts[i % len(self.test_texts)]): i 
                for i in range(num_requests)
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_text):
                result = future.result()
                results.append(result)
        
        total_time = time.time() - start_time
        self._analyze_results(results, "å¹¶å‘æµ‹è¯•", total_time)
    
    def load_test(self, duration=60, requests_per_second=10):
        """è´Ÿè½½æµ‹è¯•ï¼šæŒç»­ä¸€æ®µæ—¶é—´çš„é«˜é¢‘è¯·æ±‚"""
        print(f"\nâš¡ è´Ÿè½½æµ‹è¯•ï¼š{duration}ç§’ï¼Œæ¯ç§’{requests_per_second}ä¸ªè¯·æ±‚")
        print("=" * 50)
        
        results = []
        start_time = time.time()
        request_count = 0
        
        while time.time() - start_time < duration:
            batch_start = time.time()
            
            # å‘é€ä¸€æ‰¹è¯·æ±‚
            with ThreadPoolExecutor(max_workers=requests_per_second) as executor:
                batch_futures = [
                    executor.submit(self.single_request_test, self.test_texts[i % len(self.test_texts)])
                    for i in range(requests_per_second)
                ]
                
                for future in as_completed(batch_futures):
                    result = future.result()
                    results.append(result)
                    request_count += 1
            
            # æ§åˆ¶è¯·æ±‚é¢‘ç‡
            batch_time = time.time() - batch_start
            if batch_time < 1.0:
                time.sleep(1.0 - batch_time)
        
        total_time = time.time() - start_time
        self._analyze_results(results, "è´Ÿè½½æµ‹è¯•", total_time)
    
    def stress_test(self, max_concurrent=50):
        """å‹åŠ›æµ‹è¯•ï¼šé€æ­¥å¢åŠ å¹¶å‘æ•°"""
        print(f"\nğŸ’¥ å‹åŠ›æµ‹è¯•ï¼šæœ€å¤§{max_concurrent}ä¸ªå¹¶å‘")
        print("=" * 50)
        
        concurrent_levels = [1, 5, 10, 20, 30, 50]
        stress_results = {}
        
        for concurrency in concurrent_levels:
            if concurrency > max_concurrent:
                break
                
            print(f"\næµ‹è¯•å¹¶å‘æ•°: {concurrency}")
            results = []
            start_time = time.time()
            
            with ThreadPoolExecutor(max_workers=concurrency) as executor:
                futures = [
                    executor.submit(self.single_request_test, self.test_texts[i % len(self.test_texts)])
                    for i in range(concurrency * 2)  # æ¯ä¸ªå¹¶å‘çº§åˆ«å‘é€2å€è¯·æ±‚
                ]
                
                for future in as_completed(futures):
                    result = future.result()
                    results.append(result)
            
            total_time = time.time() - start_time
            analysis = self._analyze_results(results, f"å‹åŠ›æµ‹è¯•({concurrency}å¹¶å‘)", total_time, verbose=False)
            stress_results[concurrency] = analysis
            
            # å¦‚æœé”™è¯¯ç‡è¿‡é«˜ï¼Œåœæ­¢æµ‹è¯•
            if analysis['error_rate'] > 0.1:  # 10%é”™è¯¯ç‡
                print(f"âš ï¸  é”™è¯¯ç‡è¿‡é«˜({analysis['error_rate']:.1%})ï¼Œåœæ­¢å‹åŠ›æµ‹è¯•")
                break
        
        return stress_results
    
    def _analyze_results(self, results, test_name, total_time=None, verbose=True):
        """åˆ†ææµ‹è¯•ç»“æœ"""
        successful_results = [r for r in results if r["success"]]
        failed_results = [r for r in results if not r["success"]]
        
        total_requests = len(results)
        successful_requests = len(successful_results)
        failed_requests = len(failed_results)
        
        if successful_requests == 0:
            print(f"âŒ {test_name}: æ‰€æœ‰è¯·æ±‚éƒ½å¤±è´¥äº†ï¼")
            return {
                "total_requests": total_requests,
                "successful_requests": 0,
                "failed_requests": failed_requests,
                "error_rate": 1.0,
                "avg_response_time": 0,
                "min_response_time": 0,
                "max_response_time": 0,
                "throughput": 0
            }
        
        # å“åº”æ—¶é—´ç»Ÿè®¡
        response_times = [r["response_time"] for r in successful_results]
        avg_response_time = statistics.mean(response_times)
        min_response_time = min(response_times)
        max_response_time = max(response_times)
        median_response_time = statistics.median(response_times)
        p95_response_time = np.percentile(response_times, 95)
        
        # ååé‡è®¡ç®—
        if total_time:
            throughput = successful_requests / total_time
        else:
            throughput = 0
        
        # é”™è¯¯ç‡
        error_rate = failed_requests / total_requests if total_requests > 0 else 0
        
        if verbose:
            print(f"\nğŸ“Š {test_name} ç»“æœåˆ†æ:")
            print(f"   æ€»è¯·æ±‚æ•°: {total_requests}")
            print(f"   æˆåŠŸè¯·æ±‚: {successful_requests}")
            print(f"   å¤±è´¥è¯·æ±‚: {failed_requests}")
            print(f"   é”™è¯¯ç‡: {error_rate:.2%}")
            print(f"   å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}ms")
            print(f"   ä¸­ä½æ•°å“åº”æ—¶é—´: {median_response_time:.2f}ms")
            print(f"   95%åˆ†ä½å“åº”æ—¶é—´: {p95_response_time:.2f}ms")
            print(f"   æœ€å°å“åº”æ—¶é—´: {min_response_time:.2f}ms")
            print(f"   æœ€å¤§å“åº”æ—¶é—´: {max_response_time:.2f}ms")
            if throughput > 0:
                print(f"   ååé‡: {throughput:.2f} è¯·æ±‚/ç§’")
        
        return {
            "total_requests": total_requests,
            "successful_requests": successful_requests,
            "failed_requests": failed_requests,
            "error_rate": error_rate,
            "avg_response_time": avg_response_time,
            "median_response_time": median_response_time,
            "p95_response_time": p95_response_time,
            "min_response_time": min_response_time,
            "max_response_time": max_response_time,
            "throughput": throughput
        }
    
    def run_full_test_suite(self):
        """è¿è¡Œå®Œæ•´çš„æ€§èƒ½æµ‹è¯•å¥—ä»¶"""
        print("ğŸ¯ BERTä¸­æ–‡æ–‡æœ¬åˆ†ç±»APIæ€§èƒ½æµ‹è¯•")
        print("=" * 60)
        print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ç›®æ ‡æœåŠ¡: {self.base_url}")
        print("=" * 60)
        
        # 1. åŸºçº¿æµ‹è¯•
        self.baseline_test(num_requests=10)
        
        # 2. å¹¶å‘æµ‹è¯•
        self.concurrent_test(num_requests=50, max_workers=10)
        
        # 3. è´Ÿè½½æµ‹è¯•
        self.load_test(duration=30, requests_per_second=5)  # ç¼©çŸ­æµ‹è¯•æ—¶é—´
        
        # 4. å‹åŠ›æµ‹è¯•
        stress_results = self.stress_test(max_concurrent=30)
        
        # 5. æ€»ç»“æŠ¥å‘Š
        self._print_summary_report(stress_results)
    
    def _print_summary_report(self, stress_results):
        """æ‰“å°æ€»ç»“æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“‹ æ€§èƒ½æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
        print("=" * 60)
        
        if not stress_results:
            print("âŒ å‹åŠ›æµ‹è¯•æœªå®Œæˆ")
            return
        
        print("å¹¶å‘æ€§èƒ½åˆ†æ:")
        print(f"{'å¹¶å‘æ•°':<8} {'å¹³å‡å“åº”æ—¶é—´(ms)':<18} {'95%åˆ†ä½(ms)':<15} {'ååé‡(è¯·æ±‚/ç§’)':<18} {'é”™è¯¯ç‡':<8}")
        print("-" * 70)
        
        for concurrency, result in stress_results.items():
            print(f"{concurrency:<8} {result['avg_response_time']:<18.2f} "
                  f"{result['p95_response_time']:<15.2f} {result['throughput']:<18.2f} "
                  f"{result['error_rate']:<8.2%}")
        
        # æ€§èƒ½å»ºè®®
        print("\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
        
        # æ‰¾åˆ°æœ€ä½³å¹¶å‘æ•°
        best_concurrency = max(stress_results.keys(), 
                              key=lambda x: stress_results[x]['throughput'])
        best_result = stress_results[best_concurrency]
        
        print(f"   1. æ¨èå¹¶å‘æ•°: {best_concurrency} (ååé‡: {best_result['throughput']:.2f} è¯·æ±‚/ç§’)")
        
        if best_result['avg_response_time'] > 1000:
            print("   2. å“åº”æ—¶é—´è¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–æ¨¡å‹æ¨ç†æ€§èƒ½")
        
        if best_result['error_rate'] > 0.05:
            print("   3. é”™è¯¯ç‡è¾ƒé«˜ï¼Œå»ºè®®æ£€æŸ¥æœåŠ¡ç¨³å®šæ€§")
        
        print("   4. è€ƒè™‘å¢åŠ Gunicorn workeræ•°é‡æå‡å¹¶å‘èƒ½åŠ›")
        print("   5. å¯ä»¥éƒ¨ç½²å¤šä¸ªæ¨ç†æœåŠ¡å®ä¾‹è¿›è¡Œè´Ÿè½½å‡è¡¡")

if __name__ == "__main__":
    # åˆ›å»ºæµ‹è¯•å™¨å®ä¾‹
    tester = PerformanceTester()
    
    # è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
    tester.run_full_test_suite() 